{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c24dac5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/14/25 16:34:18] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Submitted: respiratory-viruses, activity-levels;                       <a href=\"file:///tmp/ipykernel_775298/128420152.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128420152.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_775298/128420152.py#56\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">56</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/14/25 16:34:18]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Submitted: respiratory-viruses, activity-levels;                       \u001b]8;id=594711;file:///tmp/ipykernel_775298/128420152.py\u001b\\\u001b[2m128420152.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=979585;file:///tmp/ipykernel_775298/128420152.py#56\u001b\\\u001b[2m56\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/14/25 16:34:19] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Scraping: respiratory-viruses, activity-levels;                        <a href=\"file:///tmp/ipykernel_775298/128420152.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128420152.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_775298/128420152.py#72\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">72</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/14/25 16:34:19]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Scraping: respiratory-viruses, activity-levels;                        \u001b]8;id=812382;file:///tmp/ipykernel_775298/128420152.py\u001b\\\u001b[2m128420152.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=160392;file:///tmp/ipykernel_775298/128420152.py#72\u001b\\\u001b[2m72\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/14/25 16:34:50] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Completed: respiratory-viruses, activity-levels;                       <a href=\"file:///tmp/ipykernel_775298/128420152.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128420152.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_775298/128420152.py#69\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">69</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/14/25 16:34:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Completed: respiratory-viruses, activity-levels;                       \u001b]8;id=397195;file:///tmp/ipykernel_775298/128420152.py\u001b\\\u001b[2m128420152.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=843685;file:///tmp/ipykernel_775298/128420152.py#69\u001b\\\u001b[2m69\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/14/25 16:35:21] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Submitted: covid-data-tracker, #variant-proportions;                   <a href=\"file:///tmp/ipykernel_775298/128420152.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128420152.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_775298/128420152.py#56\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">56</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/14/25 16:35:21]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Submitted: covid-data-tracker, #variant-proportions;                   \u001b]8;id=986470;file:///tmp/ipykernel_775298/128420152.py\u001b\\\u001b[2m128420152.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=17855;file:///tmp/ipykernel_775298/128420152.py#56\u001b\\\u001b[2m56\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/14/25 16:35:22] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Scraping: covid-data-tracker, #variant-proportions;                    <a href=\"file:///tmp/ipykernel_775298/128420152.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128420152.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_775298/128420152.py#72\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">72</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/14/25 16:35:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Scraping: covid-data-tracker, #variant-proportions;                    \u001b]8;id=449773;file:///tmp/ipykernel_775298/128420152.py\u001b\\\u001b[2m128420152.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=971401;file:///tmp/ipykernel_775298/128420152.py#72\u001b\\\u001b[2m72\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/14/25 16:35:54] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Completed: covid-data-tracker, #variant-proportions;                   <a href=\"file:///tmp/ipykernel_775298/128420152.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128420152.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_775298/128420152.py#69\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">69</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/14/25 16:35:54]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Completed: covid-data-tracker, #variant-proportions;                   \u001b]8;id=721563;file:///tmp/ipykernel_775298/128420152.py\u001b\\\u001b[2m128420152.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=626905;file:///tmp/ipykernel_775298/128420152.py#69\u001b\\\u001b[2m69\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/14/25 16:36:24] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Submitted: nwss, COVID19-variants                                      <a href=\"file:///tmp/ipykernel_775298/128420152.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128420152.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_775298/128420152.py#86\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">86</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/14/25 16:36:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Submitted: nwss, COVID19-variants                                      \u001b]8;id=908746;file:///tmp/ipykernel_775298/128420152.py\u001b\\\u001b[2m128420152.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=717721;file:///tmp/ipykernel_775298/128420152.py#86\u001b\\\u001b[2m86\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/14/25 16:36:25] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Submitted: nwss, COVID19-nationaltrend                                 <a href=\"file:///tmp/ipykernel_775298/128420152.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128420152.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_775298/128420152.py#86\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">86</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/14/25 16:36:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Submitted: nwss, COVID19-nationaltrend                                 \u001b]8;id=203193;file:///tmp/ipykernel_775298/128420152.py\u001b\\\u001b[2m128420152.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=134454;file:///tmp/ipykernel_775298/128420152.py#86\u001b\\\u001b[2m86\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Scraping: nwss, COVID19-variants, retrying in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> seconds<span style=\"color: #808000; text-decoration-color: #808000\">...</span>           <a href=\"file:///tmp/ipykernel_775298/128420152.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128420152.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_775298/128420152.py#102\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">102</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Scraping: nwss, COVID19-variants, retrying in \u001b[1;36m30\u001b[0m seconds\u001b[33m...\u001b[0m           \u001b]8;id=98757;file:///tmp/ipykernel_775298/128420152.py\u001b\\\u001b[2m128420152.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=659183;file:///tmp/ipykernel_775298/128420152.py#102\u001b\\\u001b[2m102\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Scraping: nwss, COVID19-nationaltrend, retrying in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> seconds<span style=\"color: #808000; text-decoration-color: #808000\">...</span>      <a href=\"file:///tmp/ipykernel_775298/128420152.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128420152.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_775298/128420152.py#102\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">102</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Scraping: nwss, COVID19-nationaltrend, retrying in \u001b[1;36m30\u001b[0m seconds\u001b[33m...\u001b[0m      \u001b]8;id=472169;file:///tmp/ipykernel_775298/128420152.py\u001b\\\u001b[2m128420152.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=974425;file:///tmp/ipykernel_775298/128420152.py#102\u001b\\\u001b[2m102\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/14/25 16:36:56] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Completed: nwss, COVID19-nationaltrend; completed                      <a href=\"file:///tmp/ipykernel_775298/128420152.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128420152.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_775298/128420152.py#99\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">99</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/14/25 16:36:56]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Completed: nwss, COVID19-nationaltrend; completed                      \u001b]8;id=714214;file:///tmp/ipykernel_775298/128420152.py\u001b\\\u001b[2m128420152.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=370666;file:///tmp/ipykernel_775298/128420152.py#99\u001b\\\u001b[2m99\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/14/25 16:36:57] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Completed: nwss, COVID19-variants; completed                           <a href=\"file:///tmp/ipykernel_775298/128420152.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128420152.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_775298/128420152.py#99\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">99</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/14/25 16:36:57]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Completed: nwss, COVID19-variants; completed                           \u001b]8;id=46886;file:///tmp/ipykernel_775298/128420152.py\u001b\\\u001b[2m128420152.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=707467;file:///tmp/ipykernel_775298/128420152.py#99\u001b\\\u001b[2m99\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import pymongo\n",
    "import asyncio\n",
    "import logging\n",
    "import aiohttp\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "load_dotenv()\n",
    "mcp = FastMCP(\"epi-crawl\")\n",
    "TIME_NOW = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "TIMEGEP_SEC = 30\n",
    "\n",
    "class FireCrawlRateLimitExceeded(Exception):\n",
    "    def __init__(self, message):\n",
    "        super().__init__(message)\n",
    "        self.message = message\n",
    "    def __str__(self):\n",
    "        return f\"FireCrawlRateLimitExceeded: {self.message}\"\n",
    "\n",
    "class FireCrawl:\n",
    "    def __init__(self, url):\n",
    "        \n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.FIRECRAWL_API_KEY = os.getenv('FIRECRAWL_API_KEY')\n",
    "        self.FIRECRAWL_ENDPOINT = os.getenv('FIRECRAWL_ENDPOINT')\n",
    "        self.url = url\n",
    "        self.url_snap = url.split('/')[3] + ', ' + url.split('/')[-1].split('.')[0]\n",
    "        \n",
    "        self.payload = {\n",
    "            \"url\": url,\n",
    "            \"scrapeOptions\": {\n",
    "                \"formats\": [\"html\"]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.headers = {\n",
    "            \"Authorization\": f\"Bearer {self.FIRECRAWL_API_KEY}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "    \n",
    "    def crawl(self) -> BeautifulSoup:\n",
    "        \n",
    "        #POST\n",
    "        response = requests.request(\"POST\", self.FIRECRAWL_ENDPOINT, json=self.payload, headers=self.headers) # type: ignore\n",
    "        response_json = json.loads(response.text)\n",
    "        \n",
    "        while True:\n",
    "            if response_json['success']:\n",
    "                res_url = response_json['url']\n",
    "                self.logger.info(f\"Submitted: {self.url_snap};\")\n",
    "                break\n",
    "            elif 'Rate limit exceeded' in response_json['error']:\n",
    "                raise FireCrawlRateLimitExceeded(f\"{response_json['error']}\")\n",
    "            else:\n",
    "                self.logger.error(f\"{self.url_snap}; {response_json['error']}, retrying in {TIMEGEP_SEC} seconds...\")\n",
    "                time.sleep(TIMEGEP_SEC)\n",
    "        \n",
    "        #GET\n",
    "        while True:\n",
    "            response = requests.request(\"GET\", res_url, headers=self.headers)\n",
    "            response_json = json.loads(response.text)\n",
    "            if response_json['status'] == 'completed':\n",
    "                self.logger.info(f\"Completed: {self.url_snap};\")\n",
    "                break\n",
    "            elif response_json['status'] == 'scraping':\n",
    "                self.logger.info(f\"Scraping: {self.url_snap};\")\n",
    "                time.sleep(TIMEGEP_SEC)\n",
    "        soup = BeautifulSoup(response_json['data'][0]['html'], 'html.parser')\n",
    "        return soup\n",
    "\n",
    "    async def crawl_async(self, session) -> BeautifulSoup:\n",
    "        \n",
    "        # POST\n",
    "        async with session.post(self.FIRECRAWL_ENDPOINT, json=self.payload, headers=self.headers) as response:\n",
    "            response_json = await response.json()\n",
    "            \n",
    "            while True:\n",
    "                if response_json['success']:\n",
    "                    res_url = response_json['url'].replace(\"https:\", self.FIRECRAWL_ENDPOINT.split('//')[0]) # type: ignore\n",
    "                    self.logger.info(f\"Submitted: {self.url_snap}\")\n",
    "                    break\n",
    "                elif 'Rate limit exceeded' in response_json['error']:\n",
    "                    raise Exception(f\"{response_json['error']}\")\n",
    "                else:\n",
    "                    self.logger.error(f\"{self.url_snap}; {response_json['error']}, retrying in {TIMEGEP_SEC} seconds...\")\n",
    "                    time.sleep(TIMEGEP_SEC)\n",
    "\n",
    "        # GET\n",
    "        while True:\n",
    "            async with session.get(res_url, headers=self.headers) as response:\n",
    "                response_json = await response.json()\n",
    "                if response_json['status'] == 'completed':\n",
    "                    self.logger.info(f\"Completed: {self.url_snap}; {response_json['status']}\")\n",
    "                    break\n",
    "                elif response_json['status'] == 'scraping':\n",
    "                    self.logger.info(f\"Scraping: {self.url_snap}, retrying in {TIMEGEP_SEC} seconds...\")\n",
    "                    await asyncio.sleep(TIMEGEP_SEC)\n",
    "        soup = BeautifulSoup(response_json['data'][0]['html'], 'html.parser')\n",
    "        return soup\n",
    "\n",
    "@mcp.tool()\n",
    "async def crawl_2_url(url_1, url_2):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [FireCrawl(url).crawl_async(session) for url in [url_1, url_2]]\n",
    "        soup_list = await asyncio.gather(*tasks)\n",
    "    return soup_list\n",
    "\n",
    "# @mcp.tool()\n",
    "# async def get_us_epidata():\n",
    "\n",
    "url_us = {\n",
    "    'all_respiratory_viruses': {\n",
    "        'summary': 'https://www.cdc.gov/respiratory-viruses/data/activity-levels.html',\n",
    "        'trends': 'https://www.cdc.gov/respiratory-viruses/data/activity-levels.html'\n",
    "    },\n",
    "    'clinical_cov': {\n",
    "        'trends': 'same with all_respiratory_viruses > trends > COVID-19_percent_of_tests_positive',\n",
    "        'variants': 'https://covid.cdc.gov/covid-data-tracker/#variant-proportions'\n",
    "    },\n",
    "    'wastewater_cov': {\n",
    "        'trends': 'https://www.cdc.gov/nwss/rv/COVID19-nationaltrend.html',\n",
    "        'variants': 'https://www.cdc.gov/nwss/rv/COVID19-variants.html'\n",
    "    }\n",
    "}\n",
    "\n",
    "## all_respiratory_viruses & clinical_cov trends\n",
    "arv_soup = FireCrawl(url_us['all_respiratory_viruses']['summary']).crawl()\n",
    "arv_summary_str = arv_soup.find('div', class_='update-snapshot').text.strip() # type: ignore\n",
    "arv_summary = [\n",
    "    {\n",
    "    'date': str(datetime.strptime(''.join(arv_summary_str.split()[4:8])[:-3], '%A,%B%d,%Y').replace(tzinfo=timezone.utc)),\n",
    "    'virus_type': 'all respiratory viruses',\n",
    "    'summary': arv_summary_str\n",
    "    }\n",
    "]\n",
    "arv_trends  = []\n",
    "cc_cov_trends = []\n",
    "for row in arv_soup.find_all('div', class_='table-container')[-1].find('tbody').find_all('tr'): # type: ignore\n",
    "    cells = row.find_all('td') # type: ignore\n",
    "    arv_trends_td = {\n",
    "        'date': str(datetime.strptime(cells[0].text.strip(), '%B %d, %Y').replace(tzinfo=timezone.utc)),\n",
    "        'virus_type': 'all respiratory viruses',\n",
    "        'COVID-19_percent_of_tests_positive': float(cells[1].text.strip()),\n",
    "        'Influenza_percent_of_tests_positive': float(cells[2].text.strip()),\n",
    "        'RSV_percent_of_tests_positive': float(cells[3].text.strip())\n",
    "    }\n",
    "    cov_td = {\n",
    "        'date': str(datetime.strptime(cells[0].text.strip(), '%B %d, %Y').replace(tzinfo=timezone.utc)),\n",
    "        'virus_type': 'COVID-19',\n",
    "        'COVID-19_percent_of_tests_positive': float(cells[1].text.strip())\n",
    "    }\n",
    "    arv_trends.append(arv_trends_td)\n",
    "    cc_cov_trends.append(cov_td)\n",
    "    \n",
    "time.sleep(TIMEGEP_SEC)\n",
    "\n",
    "## clinical_cov variants\n",
    "def filter_by_maxwidth(div_list, max_width):\n",
    "    filtered_divs = []\n",
    "    for div in div_list:\n",
    "        style_content = div['style']\n",
    "        for style in style_content.split(';'):\n",
    "            if 'max-width' in style:\n",
    "                width = style.split(':')[1].strip()\n",
    "                if width == max_width:\n",
    "                    filtered_divs.append(div)\n",
    "    return [i.text for i in filtered_divs]\n",
    "\n",
    "cc_cov_variants_soup = FireCrawl(url_us['clinical_cov']['variants']).crawl()\n",
    "cc_cov_raw_soup = cc_cov_variants_soup.select('#circulatingVariants')[0]\n",
    "cc_cov_variants_list = cc_cov_raw_soup.find_all('div', class_ = 'tab-vizHeaderWrapper')\n",
    "cc_cov_variant_name = filter_by_maxwidth([i.select('.tab-vizHeader')[0] for i in cc_cov_variants_list], '88px')\n",
    "cc_cov_variant_ratio = filter_by_maxwidth([i.select('.tab-vizHeader')[0] for i in cc_cov_variants_list], '64px')[1:]\n",
    "cc_cov_variants = [\n",
    "    {\n",
    "    'date': str(datetime.strptime(cc_cov_variants_list[-1].text, '%m/%d/%y').replace(tzinfo=timezone.utc)),\n",
    "    'virus_type': 'COVID-19',\n",
    "    'percentage': ';'.join([f\"{voc}:{float(ratio[:-1])/100:.2f}\" for voc, ratio in zip(cc_cov_variant_name, cc_cov_variant_ratio)]) + ';'\n",
    "    }\n",
    "]\n",
    "time.sleep(TIMEGEP_SEC)\n",
    "\n",
    "## wastewater_cov\n",
    "ww_cov_soup_list = await crawl_2_url(url_us['wastewater_cov']['trends'], url_us['wastewater_cov']['variants'])\n",
    "ww_cov_trends = []\n",
    "for row in ww_cov_soup_list[0].find('div', class_='table-container').find('tbody').find_all('tr'):\n",
    "    cov_td = {\n",
    "        'date': str(datetime.strptime(row.find('td').text.strip(), '%m/%d/%y').replace(tzinfo=timezone.utc)),\n",
    "        'virus_type': 'COVID-19',\n",
    "        'COVID-19_NWSS_wastewater_viral_activity_levels': float(row.find_all('td')[1].text.strip())\n",
    "    }\n",
    "    ww_cov_trends.append(cov_td)\n",
    "time.sleep(TIMEGEP_SEC)\n",
    "\n",
    "ww_cov_variants = []\n",
    "ww_cov_variants_soup = ww_cov_soup_list[1].find('div', class_='table-container')\n",
    "ww_cov_variants_name = [i.text.split('Press')[0].strip() for i in ww_cov_variants_soup.find('thead').find_all('th')]\n",
    "ww_cov_variants_name[0] = 'Date'\n",
    "for row in ww_cov_variants_soup.find('tbody').find_all('tr'):\n",
    "    cells = row.find_all('td')\n",
    "    ww_cov_var = dict(zip(ww_cov_variants_name, [i.text.strip() for i in cells]))\n",
    "    ww_cov_td = {\n",
    "        'date': str(datetime.strptime(ww_cov_var['Date'], '%Y-%m-%d').replace(tzinfo=timezone.utc)),\n",
    "        'virus_type': 'COVID-19',\n",
    "        'percentage': ';'.join([f\"{voc}:{float(partio[:-1]) / 100:.2f}\" for voc, partio in ww_cov_var.items() if voc != 'Date' and partio != 'N/A'])\n",
    "    }\n",
    "    ww_cov_variants.append(ww_cov_td)\n",
    "time.sleep(TIMEGEP_SEC)\n",
    "\n",
    "epi_us = {\n",
    "    'all_respiratory_viruses': {\n",
    "        'summary': arv_summary,\n",
    "        'trends': arv_trends\n",
    "    },\n",
    "    'clinical_cov': {\n",
    "        'trends': cc_cov_trends,\n",
    "        'variants': cc_cov_variants\n",
    "    },\n",
    "    'wastewater_cov': {\n",
    "        'trends': ww_cov_trends,\n",
    "        'variants': ww_cov_variants\n",
    "    }\n",
    "}\n",
    "os.makedirs('history') if not os.path.exists('history') else None\n",
    "with open(f'history/data_us_history_{TIME_NOW}.json', 'w') as f:\n",
    "    json.dump(epi_us, f, indent=4)\n",
    "\n",
    "epi_us_recent = {\n",
    "    'all_respiratory_viruses': {\n",
    "        'summary': arv_summary,\n",
    "        'trends': arv_trends[0:10]\n",
    "    },\n",
    "    'clinical_cov': {\n",
    "        'trends': cc_cov_trends[0:10],\n",
    "        'variants': cc_cov_variants[0:10]\n",
    "    },\n",
    "    'wastewater_cov': {\n",
    "        'trends': ww_cov_trends[0:10],\n",
    "        'variants': ww_cov_variants[0:10]\n",
    "    }\n",
    "}\n",
    "os.makedirs('recent') if not os.path.exists('recent') else None\n",
    "with open(f'recent/data_us_recent_{TIME_NOW}.json', 'w') as f:\n",
    "    json.dump(epi_us_recent, f, indent=4)\n",
    "\n",
    "# return epi_us, epi_us_recent\n",
    "\n",
    "@mcp.tool()\n",
    "def update_db(epi_us, epi_us_recent):\n",
    "    \n",
    "    update_record_list = []\n",
    "    logger = logging.getLogger(__name__)\n",
    "    MONGO_CLIENT = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "    MONGO_DB = MONGO_CLIENT[\"epi-crawl\"]\n",
    "    \n",
    "    def update(head, db):\n",
    "        d_head = datetime.strptime(head['date'], '%Y-%m-%d %H:%M:%S%z')\n",
    "        for i in db.find().sort('date', pymongo.DESCENDING).limit(1):\n",
    "            d_db = i['date'].replace(tzinfo=timezone.utc)\n",
    "        if d_head > d_db:\n",
    "            document = head\n",
    "            document['date'] = d_head\n",
    "            db.insert_one(document)\n",
    "            logger.info(f'🌟 update {db.name}: {str(d_db)[:10]} -> {str(d_head)[:10]}')\n",
    "            return document\n",
    "        else:\n",
    "            logger.info(f'🏖️ no update {db.name}: {str(d_db)[:10]} -> {str(d_head)[:10]}')\n",
    "            return None\n",
    "    \n",
    "    for head, db in zip(\n",
    "        [\n",
    "            epi_us['all_respiratory_viruses']['summary'][0],\n",
    "            epi_us['all_respiratory_viruses']['trends'][0],\n",
    "            epi_us['clinical_cov']['trends'][0],\n",
    "            epi_us['clinical_cov']['variants'][0],\n",
    "            epi_us['wastewater_cov']['trends'][0],\n",
    "            epi_us['wastewater_cov']['variants'][0],\n",
    "        ],\n",
    "        [\n",
    "            MONGO_DB.all_respiratory_viruses_summary,\n",
    "            MONGO_DB.all_respiratory_viruses_trends,\n",
    "            MONGO_DB.clinical_cov_trends,\n",
    "            MONGO_DB.clinical_cov_variants,\n",
    "            MONGO_DB.wastewater_cov_trends,\n",
    "            MONGO_DB.wastewater_cov_variants\n",
    "        ]\n",
    "    ):\n",
    "        update_record = update(head, db)\n",
    "        if update_record is not None:\n",
    "            update_record_list.append(update_record)\n",
    "    if len(update_record_list) == 0:\n",
    "        logger.info('🏖️ no update')\n",
    "        return\n",
    "    else:\n",
    "        MONGO_DB.recent_shortcasts.insert_one({\n",
    "            \"date\": datetime.strptime(epi_us_recent[\"all_respiratory_viruses\"][\"summary\"][0][\"date\"], '%Y-%m-%d %H:%M:%S%z').replace(tzinfo=timezone.utc),\n",
    "            \"recent\": epi_us_recent\n",
    "        })\n",
    "        logger.info(f'🌟 update recent_shortcasts: {str(epi_us_recent[\"all_respiratory_viruses\"][\"summary\"][0][\"date\"])[:10]}')\n",
    "\n",
    "    MONGO_CLIENT.close()\n",
    "    logger.info(f\"Total Updated {len(update_record_list)} items.\")\n",
    "    logger.info(f\"✅ epi-crawl updated successfully, next update in 3 days...\")\n",
    "    \n",
    "    return\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "    \n",
    "#     ## if using MCP, uncomment the following line, and comment the rest line, and run: uv run epi-crawl.py\n",
    "#     # mcp.run(transport='stdio')\n",
    "\n",
    "#     ## if not using MCP, uncomment the following line, and comment the above line, and run: python epi-crawl.py or uv run epi-crawl.py\n",
    "#     async def main():\n",
    "#         while True:\n",
    "#             try:\n",
    "#                 epi_us, epi_us_recent = await get_us_epidata()\n",
    "#                 update_db(epi_us, epi_us_recent)\n",
    "#                 time.sleep(3600 * 24 * 3)\n",
    "#             except FireCrawlRateLimitExceeded as e:\n",
    "#                 print(e)\n",
    "#                 print('⚠️ FireCrawl Rate limit exceeded, retrying in 60 seconds...')\n",
    "#                 time.sleep(60)\n",
    "#             # except:\n",
    "#             #     print('⚠️ An error occurred, retrying in 10 seconds...')\n",
    "#             #     time.sleep(10)\n",
    "\n",
    "#     asyncio.run(main())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
